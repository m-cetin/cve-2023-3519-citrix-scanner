import datetime
import argparse
import csv
import json
import logging
import requests
from concurrent.futures import ThreadPoolExecutor

requests.packages.urllib3.disable_warnings()

MAX_RETRIES = 3

PATCHED_VERSIONS = [
    {"version": "13.0-91.13", "timestamp": "Fri, 07 Jul 2023 15:39:40 GMT"},
    {"version": "13.1-49.13", "timestamp": "Mon, 10 Jul 2023 17:41:17 GMT"},
    {"version": "13.1-49.13", "timestamp": "Mon, 10 Jul 2023 18:36:14 GMT"}
]

def get_last_modified(target_url):
    for _ in range(MAX_RETRIES):
        try:
            resp = requests.get(target_url, verify=False, allow_redirects=True, timeout=10)
            last_modified = datetime.datetime.strptime(resp.headers["Last-Modified"], "%a, %d %b %Y %H:%M:%S %Z")
            return resp, last_modified
        except (KeyError, requests.exceptions.RequestException):
            continue
    return None, None

def check_vulnerability(target):
    target = f"https://{target.strip()}"
    resp, last_modified = get_last_modified(target)
    patched = False

    if resp is not None:
        for patch in PATCHED_VERSIONS:
            if last_modified == datetime.datetime.strptime(patch["timestamp"], "%a, %d %b %Y %H:%M:%S %Z"):
                patched = True
        if not patched and last_modified < datetime.datetime.strptime("01 Jul 2023 00:00:00 GMT", "%d %b %Y %H:%M:%S %Z"):
            patched = "potentially vulnerable (older than 01 Jul 2023)"
        elif not patched:
            patched = "potentially vulnerable (unknown timestamp)"
    else:
        patched = "not verifiable"
        last_modified = "N/A"

    return target, last_modified, patched

def save_results(results, output_file, output_format):
    if output_format == "csv":
        with open(output_file, "w", newline="") as csvfile:
            fieldnames = ["Target", "Last Modified", "Patched Status"]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            for result in results:
                writer.writerow({"Target": result[0], "Last Modified": result[1], "Patched Status": result[2]})
    elif output_format == "json":
        json_data = [{"Target": result[0], "Last Modified": str(result[1]), "Patched Status": result[2]} for result in results]
        with open(output_file, "w") as jsonfile:
            json.dump(json_data, jsonfile, indent=2)
    else:
        logging.warning("Invalid output format specified. Results not saved.")

def main(targets_file, output_file, output_format):
    with open(targets_file, "r") as f:
        targets = [line.strip() for line in f.readlines()]

    results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(check_vulnerability, target) for target in targets]
        for future in futures:
            result = future.result()
            results.append(result)

    save_results(results, output_file, output_format)
    logging.info("Scan completed. Results saved.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="CVE-2023-3519 Vulnerability Checker for Citrix Applications")
    parser.add_argument("targets_file", help="Path to the file containing target URLs.")
    parser.add_argument("output_file", help="Path to the output file.")
    parser.add_argument("output_format", choices=["csv", "json"], default="csv",
                        help="Output format for the scan results (csv or json).")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    logging.info("#" * 80)
    logging.info("# CVE-2023-3519-checker.py")
    logging.info("# by Deutsche Telekom CERT")
    logging.info("# Don't use this as your only way of verification!")
    logging.info("#" * 80)

    main(args.targets_file, args.output_file, args.output_format)
